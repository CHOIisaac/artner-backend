import json
import base64
from openai import OpenAI
import boto3
from decouple import config


class DocentService:
    """ë„ìŠ¨íŠ¸ ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # OpenAI ì„¤ì •
        openai_api_key = config('OPENAI_API_KEY', default='')
        if not openai_api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        self.openai_client = OpenAI(api_key=openai_api_key)
        
        # AWS Polly ì„¤ì •
        aws_access_key = config('AWS_ACCESS_KEY_ID', default='')
        aws_secret_key = config('AWS_SECRET_ACCESS_KEY', default='')
        aws_region = config('AWS_REGION', default='ap-northeast-2')

        if not aws_access_key or not aws_secret_key:
            raise ValueError("AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.polly = boto3.client(
            "polly",
            aws_access_key_id=aws_access_key,
            aws_secret_access_key=aws_secret_key,
            region_name=aws_region
        )

    async def generate_realtime_docent(
        self, 
        prompt_text: str = None,
        prompt_image: str = None,
    ) -> dict:
        """ì‹¤ì‹œê°„ ë„ìŠ¨íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        try:
            print(f"ğŸ¯ API í˜¸ì¶œë¨!")
            print(f"ğŸ“ prompt_text: {prompt_text}")
            print(f"ğŸ–¼ï¸ prompt_image: {prompt_image}")
            
            # ì…ë ¥ê°’ ê²°ì •
            if prompt_text:
                query = prompt_text
                use_image = False
            elif prompt_image:
                query = "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì„œ ë„ìŠ¨íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”"
                use_image = True
                
            print(f"ğŸ” ìµœì¢… query: {query}")
            print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì‚¬ìš©: {use_image}")
            
            print("ğŸ¤– LLMìœ¼ë¡œ ë„ìŠ¨íŠ¸ ìƒì„± ì‹œì‘...")
            
            # í†µí•© í”„ë¡¬í”„íŠ¸ - íƒ€ì… íŒë³„ê³¼ ë„ìŠ¨íŠ¸ ìƒì„±ì„ í•œ ë²ˆì—
            unified_prompt = f"""
            ë‹¹ì‹ ì€ ì „ë¬¸ ë¯¸ìˆ ê´€ ë„ìŠ¨íŠ¸ì…ë‹ˆë‹¤.

            ì…ë ¥: "{query}"

            ë¨¼ì € ì´ê²ƒì´ ì‘ê°€ëª…ì¸ì§€ ì‘í’ˆëª…ì¸ì§€ íŒë³„í•˜ê³ , ê·¸ì— ë§ëŠ” 3-4ë¶„ ë¶„ëŸ‰ì˜ ìƒì„¸í•œ ë„ìŠ¨íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

            **ì‘ë‹µ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:**
            
            TYPE: artist (ë˜ëŠ” artwork)
            NAME: [ì •í™•í•œ ì´ë¦„]
            
            [ë„ìŠ¨íŠ¸ ë‚´ìš©]

            **ì‘ê°€ì¸ ê²½ìš° (TYPE: artist):**
            - NAMEì—ëŠ” ì‘ê°€ì˜ ì •í™•í•œ í’€ë„¤ì„ì„ ê¸°ë¡ (ì˜ˆ: "ë‹¤ë¹ˆì¹˜" ì…ë ¥ ì‹œ "ë ˆì˜¤ë‚˜ë¥´ë„ ë‹¤ ë¹ˆì¹˜")
            - ì‘ê°€ì˜ ìƒì• ì™€ ë°°ê²½
            - ì£¼ìš” ì‘í’ˆê³¼ íŠ¹ì§•  
            - ì˜ˆìˆ ì‚¬ì  ì˜ë¯¸
            - í¥ë¯¸ë¡œìš´ ì¼í™”ë‚˜ ì‚¬ì‹¤

            **ì‘í’ˆì¸ ê²½ìš° (TYPE: artwork):**
            - NAMEì—ëŠ” ì‘í’ˆëª…ë§Œ ê¸°ë¡ (ì˜ˆ: "ë‹¤ë¹ˆì¹˜ì˜ ëª¨ë‚˜ë¦¬ì" ì…ë ¥ ì‹œ "ëª¨ë‚˜ë¦¬ì")
            - ì‘í’ˆì˜ ê¸°ë³¸ ì •ë³´ (ì œì‘ ì‹œê¸°, ê¸°ë²• ë“±)
            - ì‘í’ˆì˜ ì£¼ì œì™€ ì˜ë¯¸
            - ì‹œê°ì  íŠ¹ì§•ê³¼ ê¸°ë²•
            - ì—­ì‚¬ì /ë¬¸í™”ì  ë°°ê²½
            - ê°ìƒ í¬ì¸íŠ¸

            ì¹œê·¼í•˜ê³  êµìœ¡ì ì¸ í†¤ìœ¼ë¡œ, ë§ˆì¹˜ ì‹¤ì œ ë¯¸ìˆ ê´€ì—ì„œ ê°œì¸ì—ê²Œ ì„¤ëª…í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
            ë°˜ë“œì‹œ ì²« ì¤„ì— "TYPE: artist" ë˜ëŠ” "TYPE: artwork"ë¥¼, ë‘˜ì§¸ ì¤„ì— "NAME: [ì •í™•í•œ ì´ë¦„]"ì„ ëª…ì‹œí•˜ê³ , ê·¸ ë‹¤ìŒ ì¤„ë¶€í„° ë„ìŠ¨íŠ¸ ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
            
            print(f"ğŸ“¤ LLMì— ì „ì†¡í•  í”„ë¡¬í”„íŠ¸: {unified_prompt}...")
            
            if use_image and prompt_image:
                # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° GPT-4.1-nano ì‚¬ìš©
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": unified_prompt + "\n\nì œê³µëœ ì´ë¯¸ì§€ë„ í•¨ê»˜ ë¶„ì„í•´ì„œ ë” ì •í™•í•œ ì„¤ëª…ì„ í•´ì£¼ì„¸ìš”."
                            },
                            {
                                "type": "image_url",
                                "image_url": {"url": prompt_image}
                            }
                        ]
                    }
                ]
                
                response = self.openai_client.chat.completions.create(
                    model=config('OPENAI_VISION_MODEL', default='gpt-4.1-nano'),
                    messages=messages,
                    max_tokens=4096
                )
            else:
                # í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš°
                messages = [
                    {
                        "role": "user", 
                        "content": unified_prompt
                    }
                ]
                
                response = self.openai_client.chat.completions.create(
                    model=config('OPENAI_MODEL', default='gpt-4.1-nano'),
                    messages=messages
                )
            
            full_response = response.choices[0].message.content
            
            print(f"ğŸ“¥ LLM ì‘ë‹µ ë°›ìŒ!")
            print(f"ğŸ“ ì „ì²´ ì‘ë‹µ ê¸¸ì´: {len(full_response)}")
            print(f"ğŸ“„ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {full_response[:200]}...")
            
            # íƒ€ì… íŒŒì‹±
            lines = full_response.split('\n')
            final_item_type = "artist"  # ê¸°ë³¸ê°’
            final_item_name = query  # ê¸°ë³¸ê°’ (ì›ë³¸ ì…ë ¥)
            script_text = full_response  # ê¸°ë³¸ê°’
            
            # TYPEê³¼ NAME ë¼ì¸ì„ ì°¾ì•„ì„œ íŒŒì‹±
            type_line_index = -1
            name_line_index = -1
            
            for i, line in enumerate(lines):
                stripped_line = line.strip()
                
                if stripped_line.startswith('TYPE:'):
                    type_part = stripped_line.replace('TYPE:', '').strip().lower()
                    if 'artwork' in type_part:
                        final_item_type = "artwork"
                    elif 'artist' in type_part:
                        final_item_type = "artist"
                    type_line_index = i
                
                elif stripped_line.startswith('NAME:'):
                    name_part = stripped_line.replace('NAME:', '').strip()
                    if name_part:  # NAMEì´ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ
                        final_item_name = name_part
                    name_line_index = i
            
            # ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ (TYPEê³¼ NAME ë¼ì¸ ì´í›„ë¶€í„°)
            script_start_index = max(type_line_index, name_line_index) + 1
            if script_start_index < len(lines):
                script_text = '\n'.join(lines[script_start_index:]).strip()
            
            print(f"ğŸ¨ íŒŒì‹±ëœ íƒ€ì…: {final_item_type}")
            print(f"ğŸ“› íŒŒì‹±ëœ ì´ë¦„: {final_item_name}")
            print(f"ğŸ“„ ìµœì¢… ìŠ¤í¬ë¦½íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {script_text[:100]}...")
            
            # ìŒì„± ìƒì„± ì‘ì—… ì‹œì‘
            from .tasks import audio_job_manager
            audio_job_id = audio_job_manager.create_job(script_text)
            print(f"ğŸ”Š ìŒì„± ì‘ì—… ID: {audio_job_id}")
            
            result = {
                'text': script_text,
                'item_type': final_item_type,
                'item_name': final_item_name,  # íŒŒì‹±ëœ ì´ë¦„ ì‚¬ìš©
                'audio_job_id': audio_job_id
            }
            
            print(f"âœ… ìµœì¢… ê²°ê³¼ ë°˜í™˜!")
            return result
            
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            raise e

    def _generate_audio_and_timestamps(self, script_text: str) -> tuple[str, list]:
        """Amazon Pollyë¥¼ ì´ìš©í•œ ìŒì„± ë° íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±"""
        # ìŒì„± ìƒì„±
        polly_response = self.polly.synthesize_speech(
            Text=script_text,
            OutputFormat='mp3',
            VoiceId='Seoyeon'
        )
        audio_base64 = base64.b64encode(polly_response["AudioStream"].read()).decode('utf-8')
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        marks_response = self.polly.synthesize_speech(
            Text=script_text,
            OutputFormat='json',
            VoiceId='Seoyeon',
            SpeechMarkTypes=['sentence']
        )
        
        marks_raw = marks_response["AudioStream"].read().decode("utf-8").splitlines()
        timestamps = [json.loads(line) for line in marks_raw]
        
        return audio_base64, timestamps