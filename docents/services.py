import json
import base64
import httpx
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
import boto3
from decouple import config


class DocentService:
    """ë„ìŠ¨íŠ¸ ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # OpenAI ì„¤ì •
        openai_api_key = config('OPENAI_API_KEY', default='')
        if not openai_api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        self.chat_model = ChatOpenAI(
            model=config('OPENAI_MODEL', default='gpt-4'),
            api_key=openai_api_key
        )
        
        # AWS Polly ì„¤ì •
        aws_access_key = config('AWS_ACCESS_KEY_ID', default='')
        aws_secret_key = config('AWS_SECRET_ACCESS_KEY', default='')
        aws_region = config('AWS_REGION', default='ap-northeast-2')

        if not aws_access_key or not aws_secret_key:
            raise ValueError("AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.polly = boto3.client(
            "polly",
            aws_access_key_id=aws_access_key,
            aws_secret_access_key=aws_secret_key,
            region_name=aws_region
        )

    async def generate_realtime_docent(
        self, 
        prompt_text: str = None,
        prompt_image: str = None,
        artist_name: str = None,
        item_type: str = 'artist',
        item_name: str = None
    ) -> dict:
        """ì‹¤ì‹œê°„ ë„ìŠ¨íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        try:
            print(f"ğŸ¯ API í˜¸ì¶œë¨!")
            print(f"ğŸ“ prompt_text: {prompt_text}")
            print(f"ğŸ¨ artist_name: {artist_name}")
            print(f"ğŸ–¼ï¸ prompt_image: {prompt_image}")
            
            # ì…ë ¥ê°’ ê²°ì •
            if prompt_text:
                query = prompt_text
                use_image = False
            elif prompt_image:
                query = "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì„œ ë„ìŠ¨íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”"
                use_image = True
            else:
                query = artist_name or item_name or "ì•Œ ìˆ˜ ì—†ìŒ"
                use_image = False
                
            print(f"ğŸ” ìµœì¢… query: {query}")
            print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì‚¬ìš©: {use_image}")
            
            print("ğŸ¤– LLMìœ¼ë¡œ ë„ìŠ¨íŠ¸ ìƒì„± ì‹œì‘...")
            
            # í†µí•© í”„ë¡¬í”„íŠ¸ - íƒ€ì… íŒë³„ê³¼ ë„ìŠ¨íŠ¸ ìƒì„±ì„ í•œ ë²ˆì—
            unified_prompt = f"""
            ë‹¹ì‹ ì€ ì „ë¬¸ ë¯¸ìˆ ê´€ ë„ìŠ¨íŠ¸ì…ë‹ˆë‹¤.

            ì…ë ¥: "{query}"

            ë¨¼ì € ì´ê²ƒì´ ì‘ê°€ëª…ì¸ì§€ ì‘í’ˆëª…ì¸ì§€ íŒë³„í•˜ê³ , ê·¸ì— ë§ëŠ” 3-4ë¶„ ë¶„ëŸ‰ì˜ ìƒì„¸í•œ ë„ìŠ¨íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

            **ì‘ë‹µ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:**
            
            TYPE: artist (ë˜ëŠ” artwork)
            
            [ë„ìŠ¨íŠ¸ ë‚´ìš©]

            **ì‘ê°€ì¸ ê²½ìš° (TYPE: artist):**
            - ì‘ê°€ì˜ ìƒì• ì™€ ë°°ê²½
            - ì£¼ìš” ì‘í’ˆê³¼ íŠ¹ì§•  
            - ì˜ˆìˆ ì‚¬ì  ì˜ë¯¸
            - í¥ë¯¸ë¡œìš´ ì¼í™”ë‚˜ ì‚¬ì‹¤

            **ì‘í’ˆì¸ ê²½ìš° (TYPE: artwork):**
            - ì‘í’ˆì˜ ê¸°ë³¸ ì •ë³´ (ì œì‘ ì‹œê¸°, ê¸°ë²• ë“±)
            - ì‘í’ˆì˜ ì£¼ì œì™€ ì˜ë¯¸
            - ì‹œê°ì  íŠ¹ì§•ê³¼ ê¸°ë²•
            - ì—­ì‚¬ì /ë¬¸í™”ì  ë°°ê²½
            - ê°ìƒ í¬ì¸íŠ¸

            ì¹œê·¼í•˜ê³  êµìœ¡ì ì¸ í†¤ìœ¼ë¡œ, ë§ˆì¹˜ ì‹¤ì œ ë¯¸ìˆ ê´€ì—ì„œ ì„¤ëª…í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
            ë°˜ë“œì‹œ ì²« ì¤„ì— "TYPE: artist" ë˜ëŠ” "TYPE: artwork"ë¥¼ ëª…ì‹œí•˜ê³ , ê·¸ ë‹¤ìŒ ì¤„ë¶€í„° ë„ìŠ¨íŠ¸ ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
            
            print(f"ğŸ“¤ LLMì— ì „ì†¡í•  í”„ë¡¬í”„íŠ¸: {unified_prompt}...")
            
            if use_image and prompt_image:
                # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° GPT-4V ì‚¬ìš©
                message = HumanMessage(
                    content=[
                        {"type": "text", "text": unified_prompt + "\n\nì œê³µëœ ì´ë¯¸ì§€ë„ í•¨ê»˜ ë¶„ì„í•´ì„œ ë” ì •í™•í•œ ì„¤ëª…ì„ í•´ì£¼ì„¸ìš”."},
                        {
                            "type": "image_url",
                            "image_url": {"url": prompt_image}
                        }
                    ]
                )
            else:
                # í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš°
                message = HumanMessage(content=unified_prompt)
            
            response = self.chat_model.invoke([message])
            full_response = response.content
            
            print(f"ğŸ“¥ LLM ì‘ë‹µ ë°›ìŒ!")
            print(f"ğŸ“ ì „ì²´ ì‘ë‹µ ê¸¸ì´: {len(full_response)}")
            print(f"ğŸ“„ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {full_response[:200]}...")
            
            # íƒ€ì… íŒŒì‹±
            lines = full_response.split('\n')
            final_item_type = "artist"  # ê¸°ë³¸ê°’
            script_text = full_response  # ê¸°ë³¸ê°’
            
            for i, line in enumerate(lines):
                if line.strip().startswith('TYPE:'):
                    type_part = line.strip().replace('TYPE:', '').strip().lower()
                    if 'artwork' in type_part:
                        final_item_type = "artwork"
                    elif 'artist' in type_part:
                        final_item_type = "artist"
                    
                    # TYPE ë¼ì¸ ì´í›„ì˜ ë‚´ìš©ì„ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‚¬ìš©
                    script_text = '\n'.join(lines[i+1:]).strip()
                    break
            
            print(f"ğŸ¨ íŒŒì‹±ëœ íƒ€ì…: {final_item_type}")
            print(f"ğŸ“„ ìµœì¢… ìŠ¤í¬ë¦½íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {script_text[:100]}...")
            
            print(f"ğŸ¨ ìµœì¢… íƒ€ì…: {final_item_type}")
            
            # ìŒì„± ìƒì„± ì‘ì—… ì‹œì‘
            from .tasks import audio_job_manager
            audio_job_id = audio_job_manager.create_job(script_text)
            print(f"ğŸ”Š ìŒì„± ì‘ì—… ID: {audio_job_id}")
            
            result = {
                'text': script_text,
                'item_type': final_item_type,
                'item_name': query,
                'audio_job_id': audio_job_id
            }
            
            print(f"âœ… ìµœì¢… ê²°ê³¼ ë°˜í™˜!")
            return result
            
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            raise e

    def _generate_audio_and_timestamps(self, script_text: str) -> tuple[str, list]:
        """Amazon Pollyë¥¼ ì´ìš©í•œ ìŒì„± ë° íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±"""
        # ìŒì„± ìƒì„±
        polly_response = self.polly.synthesize_speech(
            Text=script_text,
            OutputFormat='mp3',
            VoiceId='Seoyeon'
        )
        audio_base64 = base64.b64encode(polly_response["AudioStream"].read()).decode('utf-8')
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        marks_response = self.polly.synthesize_speech(
            Text=script_text,
            OutputFormat='json',
            VoiceId='Seoyeon',
            SpeechMarkTypes=['sentence']
        )
        
        marks_raw = marks_response["AudioStream"].read().decode("utf-8").splitlines()
        timestamps = [json.loads(line) for line in marks_raw]
        
        return audio_base64, timestamps